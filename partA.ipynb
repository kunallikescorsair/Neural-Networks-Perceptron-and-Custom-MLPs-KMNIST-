{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Perceptron from scratch\n",
        "\n",
        "In this assignment, we will be reimplementing a Neural Networks from scratch.\n",
        "\n",
        "In part A, we are going to build a simple Perceptron on a small dataset that contains only 3 features.\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1aUtXFBMKUumwfZ-2jmR5SIvNYPaD-t2x' width=\"500\" height=\"250\">\n",
        "\n",
        "Some of the code have already been defined for you. You need only to add your code in the sections specified (marked with **TODO**). Some assert statements have been added to verify the expected outputs are correct. If it does throw an error, this means your implementation is not behaving as expected.\n",
        "\n",
        "Note: You are only allowed to use Numpy and Pandas packages for the implemention of Perceptron. You can not packages such as Sklearn or Tensorflow."
      ],
      "metadata": {
        "id": "-kcF6GRPRK8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import Required Packages\n",
        "\n",
        "[1.1] We are going to use numpy and random packages"
      ],
      "metadata": {
        "id": "wUg1PkpnZAya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "2rit905Vv-4-"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Define Dataset\n",
        "\n",
        "[2.1] We are going to use a simple dataset containing 3 features and 7 observations. The target variable is a binary outcome (either 0 or 1)"
      ],
      "metadata": {
        "id": "oFznxXvATvMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input dataset with 3 features and corresponding binary labels\n",
        "input_set = np.array([[0,1,0], [0,0,1], [1,0,0], [1,1,0], [1,1,1], [0,1,1], [0,1,0]])\n",
        "labels = np.array([[1], [0], [0], [1], [1], [0], [1]])"
      ],
      "metadata": {
        "id": "CPN-_r8FLCgS"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Set Initial Parameters"
      ],
      "metadata": {
        "id": "SyYmv5E0T3XP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3.1] Let's set the seed in order to have reproducible outcomes"
      ],
      "metadata": {
        "id": "W9kp1UWFUc9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed to ensure reproducible results\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "RgolHUMVT8GA"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3.2] **TODO**: Define a function that will create a Numpy array of a given shape with random values.\n",
        "\n",
        "\n",
        "For example, `initialise_array(3,1)` will return an array of dimensions (3,1)that can look like this (values may be different):\n",
        "\n",
        "\n",
        "`array([[0.37454012],\n",
        "       [0.95071431],\n",
        "       [0.73199394]])`"
      ],
      "metadata": {
        "id": "5BFSPtVAUpf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to initialise weights/biases with small random values\n",
        "def initialise_array(*shape):\n",
        "    # Return an array with the given shape filled with small normally distributed random numbers\n",
        "    return np.random.randn(*shape) * 0.01"
      ],
      "metadata": {
        "id": "p_dorRcqVYCT"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3.3] **TODO**: Create a Numpy array of shape (3,1) called `init_weights` filled with random values using `initialise_array()` and print them."
      ],
      "metadata": {
        "id": "tRQW2pyTXHL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise weights with shape (3, 1) since we have 3 input features\n",
        "init_weights = initialise_array(3, 1)\n",
        "print(\"Initial weights:\\n\", init_weights)"
      ],
      "metadata": {
        "id": "SKg1QtPdXlQW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1185c4ab-0497-433a-d32c-3d61db72ebd0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial weights:\n",
            " [[ 0.00496714]\n",
            " [-0.00138264]\n",
            " [ 0.00647689]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3.4] **TODO**: Create a Numpy array of shape (1,) called `init_bias` filled with a random value using `initialise_array()` and print it."
      ],
      "metadata": {
        "id": "yhl-s-nNXzWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise bias as a single scalar value\n",
        "init_bias = initialise_array(1)\n",
        "print(\"Initial bias:\\n\", init_bias)"
      ],
      "metadata": {
        "id": "7GWLGBDDX6Ge",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f56e060a-b15d-4f08-a52d-96ccc0874f5b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial bias:\n",
            " [0.0152303]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3.5] Assert statements to check your created variables have the expected shapes"
      ],
      "metadata": {
        "id": "-o3y_gmFX9U3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert init_weights.shape == (3, 1)  # Validate that weights matrix matches input feature size\n",
        "assert init_bias.shape == (1,)       # Confirm that the bias is a single scalar value in an array"
      ],
      "metadata": {
        "id": "6ZKdef3yWpXh"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Define Linear Function\n",
        "In this section we are going to implement the linear function of a neuron:\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1vhfpGffqletFDzMIvWkCMR2jrHE5MBy5' width=\"500\" height=\"300\">"
      ],
      "metadata": {
        "id": "PcWYiiMWYRET"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[4.1] **TODO**: Define a function that will perform a dot product on the provided X and weights and add the bias to it"
      ],
      "metadata": {
        "id": "6LX0Yn_OYw3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the linear transformation: weighted sum of inputs plus bias\n",
        "def linear(X, weights, bias):\n",
        "    # Perform matrix multiplication between input and weights, then add bias\n",
        "    return np.dot(X, weights) + bias"
      ],
      "metadata": {
        "id": "ZKx_OQKnZ2UH"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[4.2] Assert statements to check your linear function is behaving as expected"
      ],
      "metadata": {
        "id": "wIhdbPD8bayw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the linear function using known weights and biases to verify correctness\n",
        "test_weights = [[0.37454012],[0.95071431],[0.73199394]]\n",
        "test_bias = [0.59865848]\n",
        "assert linear(X=input_set[0], weights=test_weights, bias=test_bias)[0] == 1.54937279\n",
        "assert linear(X=input_set[1], weights=test_weights, bias=test_bias)[0] == 1.3306524199999998\n",
        "assert linear(X=input_set[2], weights=test_weights, bias=test_bias)[0] == 0.9731985999999999\n",
        "assert linear(X=input_set[3], weights=test_weights, bias=test_bias)[0] == 1.9239129099999999\n",
        "assert linear(X=input_set[4], weights=test_weights, bias=test_bias)[0] == 2.65590685\n",
        "assert linear(X=input_set[5], weights=test_weights, bias=test_bias)[0] == 2.28136673\n",
        "assert linear(X=input_set[6], weights=test_weights, bias=test_bias)[0] == 1.54937279"
      ],
      "metadata": {
        "id": "BF7DDft0aOPU"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Activation Function\n",
        "\n",
        "In the forward pass, an activation function is applied on the result of the linear function. We are going to implement the sigmoid function and its derivative:\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1LK7yjCp4KBICYNvTXzILQUzQbkm7G9xC' width=\"200\" height=\"100\">\n",
        "<img src='https://drive.google.com/uc?id=1f5jUyw0wgiVufNqveeJVZnQc6pOrDJXD' width=\"300\" height=\"100\">\n"
      ],
      "metadata": {
        "id": "aPU5Rq62blmE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[5.1] **TODO**: Define a function that will implement the sigmoid function"
      ],
      "metadata": {
        "id": "rYZHAb-RdNck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sigmoid activation function (handles large values to avoid overflow)\n",
        "def sigmoid(x):\n",
        "    # Handle scalar input explicitly to avoid overflow in extreme values\n",
        "    if isinstance(x, (int, float)):\n",
        "        if x >= 500:\n",
        "            return 1.0\n",
        "        elif x <= -500:\n",
        "            return 0.0\n",
        "        else:\n",
        "            return 1 / (1 + np.exp(-x))\n",
        "    else:\n",
        "        # Clip array inputs to the range [-500, 500] for numerical stability\n",
        "        x = np.clip(x, -500, 500)\n",
        "        return 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "fmqOuw4afvrH"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[5.2] Assert statements to check your sigmoid function is behaving as expected"
      ],
      "metadata": {
        "id": "AsWa4glVf4zB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate sigmoid output for typical and extreme input values\n",
        "assert sigmoid(0) == 0.5\n",
        "assert sigmoid(1) == 0.7310585786300049\n",
        "assert sigmoid(-1) == 0.2689414213699951\n",
        "assert sigmoid(9999999999999) == 1.0\n",
        "assert sigmoid(-9999999999999) == 0.0"
      ],
      "metadata": {
        "id": "f_36rZRrLfP9"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[5.3] **TODO**: Define a function that will implement the derivative of the sigmoid function"
      ],
      "metadata": {
        "id": "MEnLWtDCgWLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Derivative of the sigmoid function: used for backpropagation\n",
        "def sigmoid_derivative(x):\n",
        "    # Apply the sigmoid function\n",
        "    s = sigmoid(x)\n",
        "\n",
        "    # Return the derivative: sigmoid(x) * (1 - sigmoid(x))\n",
        "    return s * (1 - s)"
      ],
      "metadata": {
        "id": "OG3SorjugZyS"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[5.4] Assert statements to check your sigmoid_derivative function is behaving as expected"
      ],
      "metadata": {
        "id": "vwVtASkEgeok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test sigmoid_derivative output for various input values including edge cases\n",
        "assert sigmoid_derivative(0) == 0.25\n",
        "assert sigmoid_derivative(1) == 0.19661193324148185\n",
        "assert sigmoid_derivative(-1) == 0.19661193324148185\n",
        "assert sigmoid_derivative(9999999999999) == 0.0\n",
        "assert sigmoid_derivative(-9999999999999) == 0.0"
      ],
      "metadata": {
        "id": "oVXCcUTZLUpj"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Forward Pass\n",
        "\n",
        "Now we have everything we need to implement the forward propagation"
      ],
      "metadata": {
        "id": "LMacN5l4gkim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[6.1] **TODO**: Define a function that will implement the forward pass (apply linear function on the input followed by the sigmoid activation function)"
      ],
      "metadata": {
        "id": "ticTCz4Yg1Ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward pass function: linear output passed through sigmoid\n",
        "def forward(X, weights, bias):\n",
        "    # Compute the linear transformation of inputs\n",
        "    z = linear(X, weights, bias)\n",
        "\n",
        "    # Apply the sigmoid activation function to the linear output\n",
        "    a = sigmoid(z)\n",
        "\n",
        "    # Return the final activated output\n",
        "    return a"
      ],
      "metadata": {
        "id": "FuyjHgpahKD9"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[6.2] Assert statements to check your forward function is behaving as expected"
      ],
      "metadata": {
        "id": "l4ZI4yoDhPrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm that forward pass produces expected outputs with test inputs\n",
        "assert forward(X=input_set[0], weights=test_weights, bias=test_bias)[0] == 0.8248231247647452\n",
        "assert forward(X=input_set[1], weights=test_weights, bias=test_bias)[0] == 0.7909485322272701\n",
        "assert forward(X=input_set[2], weights=test_weights, bias=test_bias)[0] == 0.7257565873271445\n",
        "assert forward(X=input_set[3], weights=test_weights, bias=test_bias)[0] == 0.8725741389540382\n",
        "assert forward(X=input_set[4], weights=test_weights, bias=test_bias)[0] == 0.9343741240208852\n",
        "assert forward(X=input_set[5], weights=test_weights, bias=test_bias)[0] == 0.9073220375080315\n",
        "assert forward(X=input_set[6], weights=test_weights, bias=test_bias)[0] == 0.8248231247647452"
      ],
      "metadata": {
        "id": "ebJmLZQtNJMQ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Calculate Error\n",
        "\n",
        "After the forward pass, the Neural Networks will calculate the error between its predictions (output of forward pass) and the actual targets."
      ],
      "metadata": {
        "id": "hLlcne6nhTiF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[7.1] **TODO**: Define a function that will implement the error calculation (difference between predictions and actual targets)"
      ],
      "metadata": {
        "id": "ucesRV6mgi5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Loss Calculation] Compute total prediction error across all samples\n",
        "# Measures the sum of differences between predicted and actual labels\n",
        "def calculate_error(actual, pred):\n",
        "    # Subtract true labels from predictions and sum the result to get total error\n",
        "    return np.sum(np.array(pred) - np.array(actual))"
      ],
      "metadata": {
        "id": "08oSjRvmh3_S"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[7.2] Assert statements to check your calculate_error function is behaving as expected"
      ],
      "metadata": {
        "id": "X5TWDZdIh_-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate error calculation by comparing predictions against actual labels\n",
        "test_actual = np.array([0,0,0,1,1,1])\n",
        "assert calculate_error(actual=test_actual, pred=[0,0,0,1,1,1]).sum() == 0\n",
        "assert calculate_error(actual=test_actual, pred=[0,0,0,1,1,0]).sum() == -1\n",
        "assert calculate_error(actual=test_actual, pred=[0,0,0,0,0,0]).sum() == -3"
      ],
      "metadata": {
        "id": "GAWsb4KpOgL4"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Calculate Gradients\n",
        "Once the error has been calculated, a Neural Networks will use this information to update its weights accordingly."
      ],
      "metadata": {
        "id": "JUulr3gZiUXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[8.1] Let's create function that calculate the gradients using the sigmoid derivative function and applying the chain rule."
      ],
      "metadata": {
        "id": "zGcDakS9imth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Backpropagation] Compute the gradient of the loss with respect to weights and bias\n",
        "# Uses the chain rule: derivative of loss w.r.t. prediction, then w.r.t. weights\n",
        "def calculate_gradients(pred, error, input):\n",
        "    # Compute derivative of the prediction (sigmoid output)\n",
        "    dpred = sigmoid_derivative(pred)\n",
        "\n",
        "    # Multiply error with derivative to get delta for each sample\n",
        "    z_del = error * dpred\n",
        "\n",
        "    # Calculate gradient of weights using input transposed\n",
        "    gradients = np.dot(input.T, z_del)\n",
        "\n",
        "    # Return both gradients and delta to be used for updating weights and bias\n",
        "    return gradients, z_del"
      ],
      "metadata": {
        "id": "pvLIqdu9QQBg"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Training\n",
        "\n",
        "Now that we built all the components of a Neural Networks, we can finally train it on our dataset."
      ],
      "metadata": {
        "id": "VS4K4qlSi0kp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[9.1] Create 2 variables called `weights` and `bias` that will respectively take the value of `init_weights` and `init_bias`"
      ],
      "metadata": {
        "id": "BcOC1D6LjKEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model parameters by copying initial weights and bias\n",
        "weights = init_weights\n",
        "bias = init_bias"
      ],
      "metadata": {
        "id": "ohEe-udeOZR1"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[9.2] Create a variable called `lr` that will be used as the learning rate for updating the weights"
      ],
      "metadata": {
        "id": "L8_DzvuqjXOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the learning rate used in gradient descent updates\n",
        "lr = 0.5"
      ],
      "metadata": {
        "id": "X2DFhqF4jJdz"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[9.3] Create a variable called `epochs` with the value 10000. This will the number of times the Neural Networks will process the entire dataset and update its weights"
      ],
      "metadata": {
        "id": "QYt-FXr2jhNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the number of training iterations (epochs) for full dataset passes\n",
        "epochs = 10000  # Number of full passes over the dataset during training"
      ],
      "metadata": {
        "id": "VS8BWdy5jlra"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[9.4] Create a for loop that will perform the training of our Neural Networks"
      ],
      "metadata": {
        "id": "zrA8T0r0j0SO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Training Loop] Repeatedly update weights and bias over multiple epochs to minimize error\n",
        "for epoch in range(epochs):\n",
        "    inputs = input_set  # Use the full training dataset for each epoch\n",
        "\n",
        "    # Perform forward pass to get predicted outputs for current weights and bias\n",
        "    z = forward(X=inputs, weights=weights, bias=bias)\n",
        "\n",
        "    # Calculate the difference between predictions and actual labels\n",
        "    error = calculate_error(actual=labels, pred=z)\n",
        "\n",
        "    # Compute gradients for weights and the intermediate delta for bias\n",
        "    gradients, z_del = calculate_gradients(pred=z, error=error, input=input_set)\n",
        "\n",
        "    # Update weights using gradient descent rule\n",
        "    weights = weights - lr * gradients\n",
        "\n",
        "    # Update bias for each training sample's delta\n",
        "    for num in z_del:\n",
        "        bias = bias - lr * num"
      ],
      "metadata": {
        "id": "VvACgpjDMPpI"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[9.5] **TODO** Print the final values of `weights` and `bias`"
      ],
      "metadata": {
        "id": "K9jYXShpkEp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display final weights and bias after training\n",
        "print(\"Final weights:\\n\", weights)\n",
        "print(\"Final bias:\\n\", bias)"
      ],
      "metadata": {
        "id": "POA_DyrRkPup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65ad00be-693f-4a19-ee18-cb0f18e1f78b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final weights:\n",
            " [[0.09721747]\n",
            " [2.34714834]\n",
            " [0.10194134]]\n",
            "Final bias:\n",
            " [-1.48227029]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Compare before and after training\n",
        "\n",
        "Let's compare the predictions of our Neural Networks before (using `init_weights` and `init_bias`) and after the training (using `weights` and `bias`)"
      ],
      "metadata": {
        "id": "XAtGwsp6iNuw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[10.1] Create a function to display the values of a single observation from the dataset (using its index), the error and the actual target and prediction"
      ],
      "metadata": {
        "id": "lU5T4iJTkv8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Final Comparison] Utility function to display the model's prediction, actual label,\n",
        "# and error for a specific input index. Helps assess model performance before and after training.\n",
        "def compare_pred(weights, bias, index, X, y):\n",
        "    # Perform a forward pass to get the model's prediction for a specific input\n",
        "    pred = forward(X=X[index], weights=weights, bias=bias)\n",
        "\n",
        "    # Extract the actual label for the same input\n",
        "    actual = y[index]\n",
        "\n",
        "    # Calculate the prediction error compared to the true label\n",
        "    error = calculate_error(actual, pred)\n",
        "\n",
        "    # Display the input, prediction, actual label, and error\n",
        "    print(f\"{X[index]} - Error {error} - Actual: {actual} - Pred: {pred}\")"
      ],
      "metadata": {
        "id": "j4yTdgGcQms5"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[10.2] Compare the results on the first observation (index 0)"
      ],
      "metadata": {
        "id": "kEK9e_0ulM-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare predictions before and after training for all data points\n",
        "# This helps visualize improvement in prediction after the model is trained\n",
        "# We compare the predicted value, actual label, and error at each index"
      ],
      "metadata": {
        "id": "VfyFa_2_dUYL"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance on the first input sample (index 0)\n",
        "compare_pred(weights=init_weights, bias=init_bias, index=0, X=input_set, y=labels)\n",
        "compare_pred(weights=weights, bias=bias, index=0, X=input_set, y=labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3FA6y1QQc-l",
        "outputId": "42419b27-8610-4d56-8a5f-6f967390e4a5"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0] - Error -0.4965381414315283 - Actual: [1] - Pred: [0.50346186]\n",
            "[0 1 0] - Error -0.2963211896026101 - Actual: [1] - Pred: [0.70367881]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[10.3] Compare the results on the second observation (index 1)"
      ],
      "metadata": {
        "id": "emEbcf13lyjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance on the second input sample (index 1)\n",
        "compare_pred(weights=init_weights, bias=init_bias, index=1, X=input_set, y=labels)\n",
        "compare_pred(weights=weights, bias=bias, index=1, X=input_set, y=labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQMJvQ_FlywM",
        "outputId": "cafe3806-9a30-49b2-b102-ee490206e845"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1] - Error 0.5054265829032935 - Actual: [0] - Pred: [0.50542658]\n",
            "[0 0 1] - Error 0.20095617436289462 - Actual: [0] - Pred: [0.20095617]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[10.4] Compare the results on the third observation (index 2)"
      ],
      "metadata": {
        "id": "BUtP4AmWld0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance on the third input sample (index 2)\n",
        "compare_pred(weights=init_weights, bias=init_bias, index=2, X=input_set, y=labels)\n",
        "compare_pred(weights=weights, bias=bias, index=2, X=input_set, y=labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imU4LVeqQTXg",
        "outputId": "26e620d0-765b-4587-c905-ee7036469bd0"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0] - Error 0.5050491883789925 - Actual: [0] - Pred: [0.50504919]\n",
            "[1 0 0] - Error 0.20019872037064 - Actual: [0] - Pred: [0.20019872]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[10.5] Compare the results on the forth observation (index 3)"
      ],
      "metadata": {
        "id": "7n7_s2EAl7M2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance on the fourth input sample (index 3)\n",
        "compare_pred(weights=init_weights, bias=init_bias, index=3, X=input_set, y=labels)\n",
        "compare_pred(weights=weights, bias=bias, index=3, X=input_set, y=labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFgNdYm0l7TD",
        "outputId": "0a91e7ad-20d2-44ff-d926-d024b69ddc35"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0] - Error -0.49529643948225954 - Actual: [1] - Pred: [0.50470356]\n",
            "[1 1 0] - Error -0.2764588337939673 - Actual: [1] - Pred: [0.72354117]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[10.6] Compare the results on the fifth observation (index 4)"
      ],
      "metadata": {
        "id": "wnr_LygFmAvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance on the fifth input sample (index 4)\n",
        "compare_pred(weights=init_weights, bias=init_bias, index=4, X=input_set, y=labels)\n",
        "compare_pred(weights=weights, bias=bias, index=4, X=input_set, y=labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euONWlvWmA1o",
        "outputId": "938b83b6-46f1-40f7-a9b8-10498bdba2e1"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1] - Error -0.4936774164107015 - Actual: [1] - Pred: [0.50632258]\n",
            "[1 1 1] - Error -0.25653876259383823 - Actual: [1] - Pred: [0.74346124]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[10.7] Compare the results on the sixth observation (index 5)"
      ],
      "metadata": {
        "id": "exRMYCRKlhI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance on the sixth input sample (index 5)\n",
        "compare_pred(weights=init_weights, bias=init_bias, index=5, X=input_set, y=labels)\n",
        "compare_pred(weights=weights, bias=bias, index=5, X=input_set, y=labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e77HEuVWQN_9",
        "outputId": "7c32c6fa-06dd-4e4a-98e8-9a3d2cc6f833"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 1] - Error 0.5050809603280083 - Actual: [0] - Pred: [0.50508096]\n",
            "[0 1 1] - Error 0.7244850808594092 - Actual: [0] - Pred: [0.72448508]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[10.8] Compare the results on the sixth observation (index 5)"
      ],
      "metadata": {
        "id": "pumbj0jHmLur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model performance on the seventh input sample (index 6)\n",
        "compare_pred(weights=init_weights, bias=init_bias, index=6, X=input_set, y=labels)\n",
        "compare_pred(weights=weights, bias=bias, index=6, X=input_set, y=labels)"
      ],
      "metadata": {
        "id": "0glVvMi5mL1s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faa95b6f-0e32-41d8-e79e-7622d4f3edaa"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0] - Error -0.4965381414315283 - Actual: [1] - Pred: [0.50346186]\n",
            "[0 1 0] - Error -0.2963211896026101 - Actual: [1] - Pred: [0.70367881]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please submit this notebook into Canvas. Name it following this rule: *assignment1-partA-\\<student_id\\>.ipynb*"
      ],
      "metadata": {
        "id": "C7SGwABjmqN7"
      }
    }
  ]
}